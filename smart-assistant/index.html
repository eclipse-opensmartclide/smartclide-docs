<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://eclipse-researchlabs.github.io/smartclide-docs/smart-assistant/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Smartclide-DLE - SmartCLIDE Docs</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Smartclide-DLE";
        var mkdocs_page_input_path = "smart-assistant/index.md";
        var mkdocs_page_url = "/smartclide-docs/smart-assistant/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> SmartCLIDE Docs
        </a>
        <div class="version">
          v1.0
        </div><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../getting-started/">Getting started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../user-guide/">User Guide</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../admin-guide/">Admin Guide</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../concepts/">Concepts</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Context Handling</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../context-handling/">Context Handling</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Service Creation</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="#">Service Creation Backend</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../service-creation-backend/">Service Creation Backend</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Service Maintenance</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="#">Backend TD Principal</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../backend-td-principal/">TD Principal Backend</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Backend TD Interest</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../backend-td-interest/">TD Interest Backend</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Backend Reusability Index</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../backend-reusability-index/">TD Reusability Index Backend</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Frontend TD & Reusability</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../frontend-td-reusability/">TD & Reusability Frontend</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Test Generation</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="#">Backend</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../backend/">Service Creation Testing</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Frontend</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../frontend/">Service Creation Testing Frontend</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Design Patterns</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../design-patterns/">Design Pattern Selection Frontend</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Service Discovery</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../service-discovery/">Service Discovery</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Smart Assistant</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Smartclide-DLE</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#requirements">Requirements</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#how-to-build-dle-component">How to Build DLE component</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#api-gateway-installation">API Gateway Installation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#sub-component-quick-installation">Sub-component Quick Installation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#how-to-run-dle-component">How to run DLE Component</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#configuration">Configuration</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#run-application">Run application</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#dle-sub-components">DLE Sub-components</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#service-classification-model">Service classification model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#code-completion-model">Code completion model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#usage_1">Usage</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#acceptance-test-suggestions-model">Acceptance test suggestions model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#case-database-initialization">Case database initialization</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#usage_2">Usage</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#add-case">Add case</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#documentation">Documentation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#predictive-model-tool-api">Predictive model tool API</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#installation">Installation</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#configuration_1">Configuration</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#bpmn-items-suggestions">BPMN Items suggestions</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#usage_3">Usage</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Runtime Monitoring & Verification</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../runtime-monitoring-verification/">SmartCLIDE-RMV</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">SmartCLIDE Docs</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Smart Assistant &raquo;</li><li>Smartclide-DLE</li>
    <li class="wy-breadcrumbs-aside">
        <a href="https://github.com/eclipse-researchlabs/smartclide-smart-assistantdocs/*docs/index.md"> Edit on </a>
    </li>
  </ul>
  <hr/>
</div>

          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="smartclide-dle">Smartclide-DLE</h1>
<p>The SmartCLIDE DLE and smart assistant has brought together the IDE assistant features within one component. Proposed models try to provide a learning algorithm with the information that data carries, including internal data history and external online web services identified from online resources.
 After providing AI models, the smart assistant and DLE models are deployed as APIs REST encapsulated in a Python package, which guarantees the portability of this component between Operating Systems. Afterward, to expose the component functionality, we have chosen to visualize these requests and responses through the API swagger, which consists of an interactive web interface.</p>
<h2 id="requirements">Requirements</h2>
<p>The list of the third-party library are listed on requirments.txt files in each sub-components; however, the two main used library and requirements are:</p>
<ul>
<li>Python 3.7+</li>
<li><a href="https://pytorch.org/">Pytorch</a></li>
<li><a href="https://huggingface.co/">HuggingFace</a></li>
<li><a href="https://scikit-learn.org">scikit-learn</a></li>
</ul>
<p>Note: The minimum requirement for installing each transformer learning models using this package is 30GB of disk storage, 2vCPU, 4GB RAM. The reason of disk storage is during package installation, and it uses temp storage and packages like a torch, which exceeds more spaces during the installation process.
To use less storage, you can disable caching behavior by using <code>--no-cache-dir</code> in pip install command. <a href="https://pip.pypa.io/en/stable/topics/caching/">more info</a> </p>
<h2 id="how-to-build-dle-component">How to Build DLE component</h2>
<p>In SmartCLIDE platform, trained models need a gateway between the trained models and user interfaces. In this regard, the smart-assistant will support this option through Flask-restx APIs developed, which serve SmartCLIDE DLE (Deep Learning Engine) and Smart Assistant. Moreover, some statistical models are supported by smart-assistant as well.In this regard, DLE needs to install both trained models sub-components and also API gateway.</p>
<h3 id="api-gateway-installation">API Gateway Installation</h3>
<p>Install prerequisites :</p>
<pre><code class="language-bash">sudo python3 -m pip install torch==1.5.1+cpu torchvision==0.6.1+cpu -f https://download.pytorch.org/whl/torch_stable.html
sudo pyton3 -m pip install git+https://github.com/Dih5/zadeh
</code></pre>
<p>install smartclid getway:</p>
<pre><code class="language-bash">sudo apt update
sudo apt install python3 python3-pip nodejs npm -y
sudo npm install -g pm2
</code></pre>
<p>After installation, SmartCLIDE smart-assistant provides the API specification using Swagger specification on "http://<SmartCLIDE-host>/dle", and "http://<SmartCLIDE-host>/iamodeler". 
In summary, the available end-points are:
- http://<SmartCLIDE-host>/dle/codegen
- http://<SmartCLIDE-host>/dle/acceptance
- http://<SmartCLIDE-host>/dle/environment
- http://<SmartCLIDE-host>/dle/templatecodegen
- http://<SmartCLIDE-host>/dle/serviceclassification
- http://<SmartCLIDE-host>/dle/bpmnitemrecommendation
- http://<SmartCLIDE-host>/dle/predictivemodeltoolassistant
- http://<SmartCLIDE-host>/iamodeler/classification/bayes
- http://<SmartCLIDE-host>/iamodeler/classification/extra-trees
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/forest
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/gradient
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/logistic
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/mlp
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/neighbors
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/sv
- http://<SmartCLIDE-host>/iamodeler/supervised/classification/tree
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/gradient
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/linear
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/mlp
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/neighbors
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/sv
- http://<SmartCLIDE-host>/iamodeler/supervised/regression/tree</p>
<h3 id="sub-component-quick-installation">Sub-component Quick Installation</h3>
<p>The trained models have been packaged using the Python Setuptools library. Therefore, this component need to install the related package by cloning the package, browsing to main directory, and executing “python3 -m pip install . --upgrade” command. </p>
<pre><code class="language-bash">git clone https://github.com/eclipse-researchlabs/smartclide-smart-assistant.git
cd smartclide-dle-models/&lt;sub-component&gt; 
python3 -m pip install . --upgrade
</code></pre>
<h2 id="how-to-run-dle-component">How to run DLE Component</h2>
<h3 id="configuration">Configuration</h3>
<p>The application configuration is set via enviroment variables:</p>
<ul>
<li><code>SA_API_PORT</code>: Port to bind to (default: <code>5001</code>). </li>
<li><code>SA_API_BIND</code>: Address to bind to (default: <code>0.0.0.0</code>).</li>
<li><code>SA_MONGODB_PORT</code>: MongoDB database to connect to (default:<code>27017</code>).</li>
<li><code>SA_MONGODB_HOST</code>: MongoDB database to connect to (default: <code>localhost</code>).</li>
<li><code>SA_MONGODB_USER</code>: MongoDB user to connect to db (default: <code>user</code>).</li>
<li><code>SA_MONGODB_PASSWROD</code>: MongoDB password to connect to db (default: <code>password</code>).</li>
<li><code>SA_MONGODB_DB</code>: MongoDB database to connect to (default: <code>smartclide-smart-assistant</code>).</li>
<li><code>DLE_BASE_URL</code>: Base URL for DLE connection (default: <code>http://smartclide.ddns.net:5001/smartclide/v1/dle</code>).</li>
<li><code>SMART_ASSISTANT_BASE_URL</code>: Base URL for Smart Assistant RabbitMQ connection (default: <code>http://smartclide.ddns.net:5000/smartclide/v1/smartassistant</code>).</li>
<li><code>RABBITMQ_HOST</code>: RabbitMQ connection string host (default: <code>localhost</code>).</li>
<li><code>RABBITMQ_PORT</code>: RabbitMQ connection string port (default: <code>5672</code>).</li>
<li><code>RABBITMQ_USER</code>: RabbitMQ connection string user (default: <code>user</code>).</li>
<li><code>RABBITMQ_PASSWORD</code>: RabbitMQ connection string password (default: <code>password</code>).</li>
<li><code>RABBITMQ_MAPPINGS</code>: RabbitMQ mappings between queue and API's endpoint to connect to. (default: <code>{
        'acceptance_tests_queue': '{SMART_ASSISTANT_BASE_URL}/acceptance',
        'bpmn_item_recommendation_queue': '{SMART_ASSISTANT_BASE_URL}/bpmnitemrecommendation',
        'code_generation_queue': '{SMART_ASSISTANT_BASE_URL}/codegen',
        'code_repo_recommendation_queue': '{SMART_ASSISTANT_BASE_URL}/coderepo',
        'enviroment_queue': '{SMART_ASSISTANT_BASE_URL}/enviroment'
    }</code>). Note: All of them are prefixed with <code>{SMART_ASSISTANT_BASE_URL}/</code> before start the connection.</li>
</ul>
<h3 id="run-application">Run application</h3>
<p>Application can be launched with the launch script:</p>
<pre><code class="language-bash">sudo bash launch.bash
</code></pre>
<p>Or using PM2:</p>
<pre><code class="language-bash">sudo pm2 start pm2.json
</code></pre>
<p>Note: if the script <code>launch.bash</code> doesn't works, you can use <code>launch2.bash</code> instead.</p>
<h2 id="dle-sub-components">DLE Sub-components</h2>
<p>SmartCLIDE primarily works with text data, therefore, these components have the advantage of text processing trends and deep learning methods. The earlier approaches mostly combined key-word based feature engineering and traditional ML. However,
the keyword-based approaches such as BoW mostly use one-
hot encoded vectors, which are high-dimensional and sparse.
The emergence of word-embedding techniques has im-
proved keyword-based feature engineering. Additionally, the
increasing word embedding of open-source projects such as
<a href="https://nlp.stanford.edu/projects/glove/">Glove</a>, <a href="https://www.nltk.org/howto/gensim.html">word2vec</a>, <a href="https://huggingface.co/docs/transformers/model_doc/bert">BERT</a>, <a href="https://huggingface.co/gpt2">GPT2</a> help the fast and efficient
low-dimensional representation of text data. Thus, despite these technologies being resource-demanding, SmartcLIDE considered them for some key functinalities.</p>
<h3 id="service-classification-model">Service classification model</h3>
<p>Smartclide provides an environment to support the development of service-oriented softwares. The goal of this service classification is to classify the same web services based on their functionality which can be helpful in later stages such as service composition. </p>
<p>The trained models have been packaged using the Python Setuptools library. Therefore, this component need to install the related package by cloning the package, browsing to main directory, and executing “python3 -m pip install . --upgrade” command. </p>
<pre><code>git clone https://github.com/eclipse-researchlabs/smartclide-smart-assistant.git
cd smartclide-dle-models/serviceclassification 
python3 -m pip install . --upgrade
</code></pre>
<p>Testing the module installation</p>
<pre><code>python3 servclassify/examples/classify_service.py
</code></pre>
<h4 id="usage">Usage</h4>
<p>This library provides two trained models; first, the prediction by ML model. Second, predict using the DL model; the default configuration uses the ML model, which is lighter. You can select method="Default" for using ML model or method= 'Advanced' for using DL model. However, the "AIPipelineConfiguration" class is configured for Default mode; for using  method= 'Advanced', you need to change the configuration in the AIPipelineConfiguration file to set service_classification_method= 'Advanced' in AIPipelineConfiguration.py and reinstall the package.</p>
<h5 id="simple-usage">Simple Usage</h5>
<pre><code class="language-python">from servclassify import PredictServiceClassModel

service_name=&quot;service name text&quot;
service_desc=&quot;find the distination on map&quot;
method=&quot;Default&quot;

predict_service_obj = PredictServiceClassModel()
result = predict_service_obj.predict(service_name, service_description, method=method)
print(result) 

</code></pre>
<p>The above class demonstrate using service classification interface class whuich is PredictServiceClassModel. After defining this class we can use it for predicting service class:</p>
<pre><code>{'result': [{'Service_name': 'service name text', 'Method': 'Default', 'Service_id': None, 'Service_class': ['Mapping', '']}]}

</code></pre>
<p>✨Note ✨
The advanced method will return the top 2 categories assigned to service metadata input. the format of output will be:</p>
<pre><code>{'result': [{'Service_name': 'service name text', 'Method': 'Default', 'Service_id': None, 'Service_class': ['Mapping', 'Transportation']}]}

</code></pre>
<h5 id="singleton-classes-usage">Singleton Classes Usage</h5>
<p>In SmartCLIDE, many tasks require to run in the background independently of the user interface (UI). AI Models is one of these tasks that need to serve requests in real-time and return results. Consequently, loading the AI model can be time-consuming due to late response. A strategy such as using singleton classes for loading the models can help minimize the application UI load, improve availability, and reduce interactive response times. </p>
<pre><code class="language-python">from typing import Tuple 
from typing import List
from servclassify import PredictServiceClassModel

class Classify_service:
    def __init__(self):
        '''
        The DL models  input parameter for PredictServiceClassModel mention loading service model
        '''
        self.predict_service_obj = PredictServiceClassModel()

    def predict(self, service_id: str, service_name: str, service_description: str, method:str = 'Default') -&gt; Tuple[str,str]:
        # predict
        result = self.predict_service_obj.predict(service_name, service_description, method=method)
        return result

#Loading model recommended to execute on background
model2 = Classify_service()
service_id=1
service_name=&quot;service name text&quot;
service_desc=&quot;find the distination on map&quot;
method=&quot;Advanced&quot;
result=model2.predict(service_id,service_name, service_desc,method)
print(result) 
</code></pre>
<p>You can find the example code which are in python script in the example folder.</p>
<h3 id="code-completion-model">Code completion model</h3>
<p>This subcomponent is responsible for generating code based on internal templates. The API returns related code snippets based on templates to implement the workflow represented in BPMN in low code. The first version of this API is designed for finding Java codes.</p>
<p>The trained models have been packaged using the Python Setuptools library. Therefore, this component need to install the related package by cloning the package, browsing to main directory, and executing “python3 -m pip install . --upgrade” command. </p>
<pre><code>git clone https://github.com/eclipse-researchlabs/smartclide-smart-assistant.git
cd smartclide-dle-models/codeautocomplete 
python3 -m pip install . --upgrade
</code></pre>
<p>Testing the module installation</p>
<pre><code>python3 servcodegen/examples/generate_code.py
</code></pre>
<h4 id="usage_1">Usage</h4>
<p>This library provides code-generator which uses language modeling, and after installation, the library can be used by importing the package. The model predicts the next tokens based on user input; in order to have better results, the following recommendation need to be considered:</p>
<ul>
<li>Max_sugges_line specifies max line suggestion; recommended value is between 1-3.</li>
<li>Max_lenth specifies max length line suggestion, and the recommended value is between 15-20</li>
<li>Use Singletone call for acceptable response time, which this method is explained in the next section.</li>
<li>Handling client requests need access to sufficient computing
infrastructure. Therefore, it suggests calling code to autocomplete when the user uses "Tab" or "Dot." </li>
</ul>
<h5 id="simple-usage_1">Simple Usage</h5>
<pre><code class="language-python">from servcodegen import AutocompleteCodeModel

model = AutocompleteCodeModel()
method=&quot;GPT-2&quot;
lang=&quot;java&quot;
max_lenth=20
max_sugges_line=3
code_input=&quot;import android.&quot;

result=model.generateCode(code_input, max_lenth, max_sugges_line,method)
print(result) 

</code></pre>
<p>The above code demonstrate using servcodegen interface class whuich is AutocompleteCodeModel. the result will be</p>
<pre><code>{'result': {'code_sugg': ['import android.os.Bundle ;', 'import android.content.Intent ;', 'import android.content.Context ;'], 'Method': 'GPT-2', 'codeSuggLen': 20, 'codeSuggLines': 3, 'language': 'java'}}
</code></pre>
<p>✨Note ✨
loding model recommended to execute on background which is explained on singletone classes usage in below.</p>
<h5 id="singleton-classes-usage_1">Singleton classes Usage</h5>
<p>In SmartCLIDE, many tasks require to run in the background independently of the user interface (UI). AI Models is one of these tasks that need to serve requests in real-time and return results. Consequently, loading the AI model can be time-consuming due to late response. A strategy such as using singleton classes for loading the models can help minimize the application UI load, improve availability, and reduce interactive response times. </p>
<pre><code class="language-python">from typing import Tuple 
from typing import List
from servcodegen import AutocompleteCodeModel

class CodeCompletion:

    def __init__(self):
        self.model = AutocompleteCodeModel()


    def predict2(self, method:str, language:str, code_input:str, code_sugg_len:int, code_sugg_lines:int) -&gt; List[str]:
        # predict
        result = self.model.generateCode(code_input, code_sugg_len, code_sugg_lines,method)
        return result

#Loading model recommended to execute on background
codecomplete_obj = CodeCompletion()

#Using loaded model
Method=&quot;GPT-2&quot;
lang=&quot;java&quot;
max_lenth=20
max_sugges_line=3
code_input=&quot;file=new&quot;
result=codecomplete_obj.predict2(Method,lang,code_input,max_lenth,max_sugges_line)
print(result) 
</code></pre>
<h3 id="acceptance-test-suggestions-model">Acceptance test suggestions model</h3>
<p>The acceptance test set suggestion system, based on collaborative filtering techniques, is responsible for providing the user with a set of tests defined in Gherkin format to be applied to the workflow defined in the BPMN and help verify if the expectations are met.</p>
<p>The trained models have been packaged using the Python Setuptools library. Therefore, this component need to install the related package by cloning the package, browsing to main directory, and executing “python3 -m pip install . --upgrade” command. </p>
<pre><code>git clone https://github.com/eclipse-researchlabs/smartclide-smart-assistant.git
cd smartclide-dle-models/cbr-gherkin-recommendation 
python3 -m pip install . --upgrade
</code></pre>
<p>To install also the dependencies to run the tests or to generate the documentation install some of the extras like (Mind the quotes):</p>
<pre><code class="language-bash">python3 -m pip install '.[docs]' --upgrade
</code></pre>
<h4 id="case-database-initialization">Case database initialization</h4>
<p>For that purpose, use the following command:</p>
<pre><code class="language-bash">python3 initialize_cbr_db.py
</code></pre>
<h4 id="usage_2">Usage</h4>
<p>The main class is CBR wich also needs the clases Casebase, Recovery and Aggregation. You need a frist load with all your base cases. After that first inicial load you can pass an empty array to the class initializer:</p>
<pre><code class="language-python">import pycbr
cbr = pycbr.CBR([],&quot;ghrkn_recommendator&quot;,&quot;smartclide.ddns.net&quot;)
</code></pre>
<h4 id="add-case">Add case</h4>
<p>The method to add a case must recibe a dictionary with this format:</p>
<pre><code class="language-python">cbr.add_case({
    'name': &quot;Sting with the file name&quot;,
    'text': &quot;All the bpmn text&quot;,
    'gherkins': [&quot;list with gherkins text&quot;]
})
</code></pre>
<h5 id="get-recommendation">Get recommendation</h5>
<p>The  method to get a recommendation must recibe a string with all the bpmn text:</p>
<pre><code class="language-python">cbr.recommend(bpmn_text)
&gt;&gt;&gt; {
        'gherkins': [[&quot;List of list with all the recomended gherkins for the first 5 matches&quot;]],
        'sims': [&quot;List of similarity scores from 0 to 1&quot;]
    }
</code></pre>
<h4 id="documentation">Documentation</h4>
<p>To generate the documentation, the <em>docs</em> extra dependencies must be installed. Furthermore, <strong>pandoc</strong> must be available in your system.</p>
<p>To generate an html documentation with sphinx run:</p>
<pre><code class="language-bash">make docs
</code></pre>
<p>To generate a PDF documentation using LaTeX:</p>
<pre><code class="language-bash">make pdf
</code></pre>
<h3 id="predictive-model-tool-api">Predictive model tool API</h3>
<p>This subcomponent utilized the automated machine learning (AutoML) concept, allowing users to define ML actions sequences via an interface.  These sequences contain the Predictive model tool APIs, which include 4 primary steps. 1) Importing data 2)  Creating a supervised model based on regression or classification Model 3) Performing Prediction based on user input 4) Providing validation matric results which can use for visualization.</p>
<h4 id="installation">Installation</h4>
<p>You probably to set up and use a virtualenv:</p>
<pre><code># Prepare a clean virtualenv and activate it
virtualenv -p /usr/bin/python3.6 venv
source venv/bin/activate
</code></pre>
<p>Remember to activate it whenever you are working with the package.</p>
<p>To install a <strong>development</strong> version clone the repo, cd to the directory and:</p>
<pre><code>pip install -e .
</code></pre>
<p>Once installed, the <em>development</em> flask server might be started with the command:</p>
<pre><code>iamodeler
</code></pre>
<p>For real deployment, gunicorn might be used instead:</p>
<pre><code>pip install gunicorn
unicorn --workers 4 --bind 0.0.0.0:5000 --timeout 600 iamodeler.server:app
</code></pre>
<p>To use a celery queue system (see configuration below), a celery broker
like <a href="https://www.rabbitmq.com/download.html">RabbitMQ</a> must also be installed.</p>
<p>With RabbitMQ installed and running, start the queue system by running:</p>
<pre><code>celery -A iamodeler.tasks.celery worker
</code></pre>
<p>Note the gunicorn timeout parameter does not affect the celery queues.</p>
<p>In <strong>Windows</strong>, the default celery pool might not work. You might try to add <code>--pool=eventlet</code> to run it.</p>
<h4 id="configuration_1">Configuration</h4>
<p>Configuration is done with environment variables.</p>
<table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>IAMODELER_STORE</td>
<td>Path to the local storage of the models. Defaults to a temporal directory.</td>
</tr>
<tr>
<td>IAMODELER_CELERY</td>
<td>If set and not empty, use a local Celery queue system.</td>
</tr>
<tr>
<td>IAMODELER_CELERY_BROKER</td>
<td>Address of the Celery broker.</td>
</tr>
<tr>
<td>IAMODELER_AUTH</td>
<td>Authentication token for the server. Client request must set X-IAMODELER-AUTH to this token in their headers.</td>
</tr>
<tr>
<td>IAMODELER_LOG</td>
<td>A path to a yaml logging configuration file. Defaults to logging.yaml</td>
</tr>
</tbody>
</table>
<p>The paths are <em>relative to the CWD</em>, provide full paths when needed.</p>
<p>Pro-tip: A .env file can be used installing the python-dotenv package.</p>
<p>An example of logging configuration file is provided in the root of the repo.</p>
<h3 id="bpmn-items-suggestions">BPMN Items suggestions</h3>
<p>This AI-based approach provides recommendations during service composition. The suggestions are based on a selected service composition approach by (BPMN-based work-flow) data representation, existing/history BPMN work-flows, and provided service specification information.</p>
<h4 id="usage_3">Usage</h4>
<p>This sub-module receives the information of the last selected node in the target BPMN diagram. This information is in JSON format, which can include unique node id and other node metadata such as name or user_id. Afterwards, the query compositor merges it with the incomplete BPMN file , developers are working with.</p>
<pre><code class="language-json">{
  &quot;dle&quot;: {
    &quot;header&quot;: &quot;bpmn suggestion&quot;,
    &quot;state&quot;: &quot;query&quot;,
    &quot;previous node&quot;: [
      {
        &quot;id&quot;: &quot;_13BAF867-3CA8-4C6F-85C6-D3FD748D07D2&quot;
      },
      {
        &quot;name&quot;: &quot;UserFound?&quot;
      }
    ]
  }
}

</code></pre>
<p>The module performs four main steps on the received JSON request, which are: 1) Query Compositor 2) Current BPMN Extractor 3) BPMN semantic identifier 4) Numerical vector transformer and finally suggesting nexrtBPMN node which will be in JSON response format: </p>
<pre><code class="language-json">
{
  &quot;dle&quot;: {
    &quot;header&quot;: &quot;bpmn suggestion&quot;,
    &quot;state&quot;: &quot;true&quot;,
    &quot;previous node&quot;: [
      {
        &quot;id&quot;: &quot;_13BAF867-3CA8-4C6F-85C6-D3FD748D07D2&quot;
      },
      {
        &quot;name&quot;: &quot;UserFound?&quot;
      }
    ],
    &quot;suggestionnode&quot;: [
      {
        &quot;id&quot;: &quot;_E5D17755-D671-43ED-BD7D-F6538933069C&quot;
      },
      {
        &quot;name&quot;: &quot;AuditUser&quot;
      }
    ]
  }
}
{
  &quot;dle&quot;: {
    &quot;header&quot;: &quot;bpmnsuggestion&quot;,
    &quot;state&quot;: &quot;false&quot;,
    &quot;previousnode&quot;: [
      {
        &quot;id&quot;: &quot;_13BAF867-3CA8-4C6F-85C6-D3FD748D07D2&quot;
      },
      {
        &quot;name&quot;: &quot;UserFound?&quot;
      }
    ]
  }
}
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../service-discovery/" class="btn btn-neutral float-left" title="Service Discovery"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../runtime-monitoring-verification/" class="btn btn-neutral float-right" title="SmartCLIDE-RMV">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright &copy; 2022 The SmartCLIDE Consortium</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../service-discovery/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../runtime-monitoring-verification/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
